{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"style_transfer.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"OIDN-lrmmIMH","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","from torch.utils.data import (Dataset,DataLoader,TensorDataset)\n","from torchvision import models\n","from torch import nn,optim\n","import tqdm\n","from torchvision import models\n","from IPython.display import Image,display_jpeg\n","from torchvision.utils import save_image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tZiWBEhcUPHP","colab_type":"text"},"cell_type":"markdown","source":["google colabで動かすときはこのセルを実行"]},{"metadata":{"id":"wToUxIFHD-lU","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls ./gdrive/'My Drive'/\"Colab Notebooks\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"6IDmncz_QUFG","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir styletrain\n","!mkdir styletrain/jpg\n","!mkdir style\n","!mkdir style/jpg\n","!mkdir sample\n","!mkdir sample/jpg　"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iVSZPsOLU7qK","colab_type":"text"},"cell_type":"markdown","source":["スタイル画像をstyle/jpg一枚のみ入れておく。また学習モニター用にサンプル画像をsample/jpgに一枚入れておく"]},{"metadata":{"id":"7BUruUZQZau9","colab_type":"code","colab":{}},"cell_type":"code","source":["style_data=ImageFolder(\"style/\",transform=transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor()]))\n","batch_size=1\n","style_loader=DataLoader(style_data,batch_size=batch_size,shuffle=True)\n","sample_data=ImageFolder(\"sample/\",transform=transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor()]))\n","batch_size=1\n","sample_loader=DataLoader(sample_data,batch_size=batch_size,shuffle=True)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K_HRWWPOVqu4","colab_type":"text"},"cell_type":"markdown","source":["1行目のパスは学習用データが入ったフォルダを選択する。"]},{"metadata":{"id":"iKl0fTFavfQn","colab_type":"code","colab":{}},"cell_type":"code","source":["train_data=ImageFolder(\"gdrive/My Drive/deeplearnning/data\",transform=transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor()]))\n","batch_size=4\n","train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qgckSlQamN9j","colab_type":"code","outputId":"500af731-7014-496e-f209-57c99e4611ad","executionInfo":{"status":"ok","timestamp":1549790467070,"user_tz":-540,"elapsed":600,"user":{"displayName":"大熊拓海","photoUrl":"","userId":"09114472068900483953"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["class ConvNormRelu(nn.Module):\n","  def __init__(self,input_feature,output_feature,batch_size,stride,padding):\n","    super().__init__() \n","    self.conv2d=nn.Conv2d(input_feature,output_feature,batch_size,stride=stride,padding=padding)\n","    self.relu=nn.ReLU()\n","    self.BatchNorm2d=nn.BatchNorm2d(output_feature)\n","  def forward(self,x):\n","    y=self.conv2d(x)\n","    y=self.BatchNorm2d(y)\n","    y=self.relu(y)\n","    return y\n","  \n","class TransConvNormRelu(nn.Module):\n","  def __init__(self,input_feature,output_feature,batch_size,stride,padding,output_padding):\n","    super().__init__() \n","    self.convtrans2d=nn.ConvTranspose2d(input_feature,output_feature,batch_size,stride,padding,output_padding=output_padding)\n","    self.relu=nn.ReLU()\n","    self.BatchNorm2d=nn.BatchNorm2d(output_feature)\n","  def forward(self,x):\n","    y=self.convtrans2d(x)\n","    y=self.BatchNorm2d(y)\n","    y=self.relu(y)\n","    return y  \n","\n","class residual(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv2d=nn.Conv2d(128,128,3,1,1)\n","    self.relu=nn.ReLU()\n","    self.BatchNorm2d=nn.BatchNorm2d(128)\n","  def forward(self,x):\n","    y=self.conv2d(x)\n","    y=self.BatchNorm2d(y)\n","    y=self.relu(y)\n","    y=self.conv2d(y)\n","    y=self.BatchNorm2d(y)\n","    y=y+x\n","    return y\n","  \n","net=nn.Sequential(\n","    ConvNormRelu(3,32,9,1,4),\n","    ConvNormRelu(32,64,3,2,1),\n","    ConvNormRelu(64,128,3,2,1),\n","    residual(),\n","    residual(),\n","    residual(),\n","    residual(),\n","    residual(),\n","    TransConvNormRelu(128,64,3,2,1,1),\n","    TransConvNormRelu(64,32,3,2,1,1),\n","    nn.ConvTranspose2d(32, 3, 9, 1, 4, bias=False),\n","    nn.BatchNorm2d(3),\n","    nn.Sigmoid()\n",")\n","\n","\n","#中間層の出力を取り出す関数\n","def midout(x,midnum,net):\n","  model=net[0:midnum+1]\n","  y = model(x)\n","  return y\n","#今回は3,8,15,22,を取り出す\n","\n","\n","vggnet=models.vgg16(pretrained=True)\n","for p in vggnet.parameters():\n","  p.requires_grad=False\n","\n","  \n","def convarray(x):\n","  size=x.size()\n","  x=x.transpose(0,1)\n","  x = x.contiguous()\n","  x=x.view(size[1],-1)\n","  conv=torch.mm(x,x.t())\n","  conv=conv/(size[0]*size[2]*size[3])\n","  return conv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.torch/models/vgg16-397923af.pth\n","100%|██████████| 553433881/553433881 [00:20<00:00, 27149817.42it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"MndKdeBJT3yy","colab_type":"code","colab":{}},"cell_type":"code","source":["style_array=[]\n","for z,_ in style_loader:\n","  x=torch.tensor(z,requires_grad=False)\n","y=midout(x,15,vggnet.features)\n","y=y.squeeze()\n","style_array.append(y)\n","\n","y=midout(x,3,vggnet.features)\n","y=convarray(y)\n","style_array.append(y)\n","y=midout(x,8,vggnet.features)\n","y=convarray(y)\n","style_array.append(y)\n","y=midout(x,15,vggnet.features)\n","y=convarray(y)\n","style_array.append(y)\n","y=midout(x,22,vggnet.features)\n","y=convarray(y)\n","style_array.append(y)  \n","\n","i=0\n","airi=[0,0]\n","for z,_ in sample_loader:\n","  airi[i]=torch.tensor(z,requires_grad=False)\n","  i+=1\n","airi[0]=airi[0].to(\"cuda:0\")\n","airi[1]=airi[1].to(\"cuda:0\")\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WsipgocgoDj0","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_net(net, net2,train_loader,target ,optimizer_cls=optim.Adam,loss_fn=nn.MSELoss(),n_iter=10, device='cpu'):\n","    train_losses=[]\n","    optimizer=optimizer_cls(net.parameters())\n","    target0=target[0].to(\"cuda:0\")\n","    target1=target[1].to(\"cuda:0\")\n","    target2=target[2].to(\"cuda:0\")\n","    target3=target[3].to(\"cuda:0\")\n","    target4=target[4].to(\"cuda:0\")\n","    #weightは重みパラメータ。スタイル画像の強さを決める\n","    #第一変数がそのほかに比べて小さいほどスタイル画像が強く表れる\n","    weight=torch.tensor([1.0,40.0,40.0,40.0,40.0])\n","    weight0=weight[0].to(\"cuda:0\")\n","    weight1=weight[1].to(device)\n","    weight2=weight[2].to(device)\n","    weight3=weight[3].to(device)\n","    weight4=weight[4].to(device)\n","    target0=target0.detach()\n","    target1=target1.detach()\n","    target2=target2.detach()\n","    target3=target3.detach()\n","    target4=target4.detach()\n","    target0.requires_grad=False\n","    target1.requires_grad=False\n","    target2.requires_grad=False\n","    target3.requires_grad=False\n","    target4.requires_grad=False\n","    for epoch in range(n_iter):\n","        running_loss=0.0\n","        net.train()\n","        n=0\n","        score=0        \n","        for i,(xx,_) in tqdm.tqdm(enumerate(train_loader),total=len(train_loader)):\n","            xx=xx.to(device)\n","            xx2=net(xx)\n","            y_pred0=midout(xx2,15,net2)\n","            target_contents=midout(xx,15,net2)\n","            loss0=loss_fn(y_pred0,target_contents)\n","            loss0/=y_pred0.size()[0]\n","            y_pred1=midout(xx2,3,net2)\n","            y_pred1=convarray(y_pred1)\n","            loss1=loss_fn(y_pred1,target1)\n","            y_pred2=midout(xx2,8,net2)\n","            y_pred2=convarray(y_pred2)\n","            loss2=loss_fn(y_pred2,target2)\n","            y_pred3=midout(xx2,15,net2)\n","            y_pred3=convarray(y_pred3)\n","            loss3=loss_fn(y_pred3,target3)\n","            y_pred4=midout(xx2,22,net2)\n","            y_pred4=convarray(y_pred4)\n","            loss4=loss_fn(y_pred4,target4)\n","            \n","            loss=weight0*loss0+weight1*loss1+weight2*loss2+weight3*loss3+weight4*loss4\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            running_loss+=loss.item()\n","            n+=len(xx)\n","            if i%40==0:\n","              torch.save(\n","                  net.state_dict(),\n","                  \"net_{:05d}.prm\".format(epoch*10000+i),\n","                  pickle_protocol=4)\n","              generated_img=net(airi[0])\n","              generated_img2=net(airi[1])\n","              gazou=torch.cat([generated_img,generated_img2],3)\n","              save_image(gazou,\"{:06d}.jpg\".format((epoch+10)*10000+i))\n","              display_jpeg(Image(\"{:06d}.jpg\".format((epoch+10)*10000+i)))\n","              print(epoch,i,loss.item())\n","              print(loss0.item(),loss1.item(),loss2.item(),loss3.item(),loss4.item())\n","        train_losses.append(running_loss/len(train_loader))\n","        print(epoch,train_losses[-1],flush=True)\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"tfPwmvf0oFTy","colab_type":"code","colab":{}},"cell_type":"code","source":["from IPython.display import Image,display_jpeg\n","from torchvision.utils import save_image\n","\n","net=net.to(\"cuda:0\")\n","vggnet=vggnet.to(\"cuda:0\")\n","train_net(net,vggnet.features,train_loader,style_array,n_iter=10,device=\"cuda:0\")\n"," #n_iterはイテレーションなので適宜変更する\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SJeZV3OZQD2g","colab_type":"text"},"cell_type":"markdown","source":["ここから下は生成タスク。"]},{"metadata":{"id":"z9AKM6zSXyTL","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir transfer\n","!mkdir transfer/jpg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JLl_HNJLYDVu","colab_type":"text"},"cell_type":"markdown","source":["変換したい画像を\"transfer/jpg\"に入れておく。\n","\n"]},{"metadata":{"id":"tv5J9tsrYvRq","colab_type":"code","colab":{}},"cell_type":"code","source":["sample_data=ImageFolder(\"transfer/\",transform=transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor()]))\n","batch_size=1\n","sample_loader=DataLoader(sample_data,batch_size=batch_size,shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0XwzYrmzpQv8","colab_type":"code","colab":{}},"cell_type":"code","source":["class ConvNormRelu(nn.Module):\n","  def __init__(self,input_feature,output_feature,batch_size,stride,padding):\n","    super().__init__() \n","    self.conv2d=nn.Conv2d(input_feature,output_feature,batch_size,stride=stride,padding=padding)\n","    self.relu=nn.ReLU()\n","    self.BatchNorm2d=nn.BatchNorm2d(output_feature)\n","  def forward(self,x):\n","    y=self.conv2d(x)\n","    y=self.BatchNorm2d(y)\n","    y=self.relu(y)\n","    return y\n","  \n","class TransConvNormRelu(nn.Module):\n","  def __init__(self,input_feature,output_feature,batch_size,stride,padding,output_padding):\n","    super().__init__() \n","    self.convtrans2d=nn.ConvTranspose2d(input_feature,output_feature,batch_size,stride,padding,output_padding=output_padding)\n","    self.relu=nn.ReLU()\n","    self.BatchNorm2d=nn.BatchNorm2d(output_feature)\n","  def forward(self,x):\n","    y=self.convtrans2d(x)\n","    y=self.BatchNorm2d(y)\n","    y=self.relu(y)\n","    return y  \n","\n","class residual(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.conv2d=nn.Conv2d(128,128,3,1,1)\n","    self.relu=nn.ReLU()\n","    self.BatchNorm2d=nn.BatchNorm2d(128)\n","  def forward(self,x):\n","    y=self.conv2d(x)\n","    y=self.BatchNorm2d(y)\n","    y=self.relu(y)\n","    y=self.conv2d(y)\n","    y=self.BatchNorm2d(y)\n","    y=y+x\n","    return y\n","\n","net=nn.Sequential(\n","    ConvNormRelu(3,32,9,1,4),\n","    ConvNormRelu(32,64,3,2,1),\n","    ConvNormRelu(64,128,3,2,1),\n","    residual(),\n","    residual(),\n","    residual(),\n","    residual(),\n","    residual(),\n","    TransConvNormRelu(128,64,3,2,1,1),\n","    TransConvNormRelu(64,32,3,2,1,1),\n","    nn.ConvTranspose2d(32, 3, 9, 1, 4, bias=False),\n","    nn.BatchNorm2d(3),\n","    nn.Tanh()\n",")\n","net=net.to(\"cuda:0\")\n","\n","#生成した最新の重みを読み込む。(パスを入力)（適宜変更）\n","params=torch.load(\"burn.prm\")\n","\n","net.load_state_dict(params)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-YnYccCcpdXz","colab_type":"code","colab":{}},"cell_type":"code","source":["from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","roop=0\n","for pic,_ in sample_loader:\n","  pic=pic.to(\"cuda:0\")\n","  save_image(pic,\"origin.jpg\".format(roop))\n","  generated_imgsub=net(pic)\n","  save_image(generated_imgsub,\"fire{:03d}.jpg\".format(roop))\n","  display_jpeg(Image(\"fire{:03d}.jpg\".format(roop)))\n","  roop+=1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xdB9kbrReX7k","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}